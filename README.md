ğŸš¨ BIG UPGRADE ALERT â€“ Sean's OmniTag Processor just leveled up from Qwen 2.5 to **Qwen 3**! ğŸ”¥ 
The old Qwen 2.5 was already savage.  
Now running **Qwen3-VL-8B-Abliterated-Caption-it** â†’ captions are noticeably sharper, more exhaustive, better object counting, spatial reasoning, fewer hallucinations, and even less censored.  
Same VRAM footprint, way better "clinical / unfiltered / zero-BS" detail.

Tired of weak, lazy, censored captions for your LoRAs / datasets?  
Say hello to **uncensored clinical detail** powered by **Qwen3-VL-8B-Abliterated-Caption-it** in ComfyUI.

<img width="344" height="393" alt="image" src="https://github.com/user-attachments/assets/9d692f5e-5806-4db1-8078-628817072c44" />


âœ¨ **What OmniTag does in one click:**

ğŸ’¾ **How to use (super easy on Windows):**

1. Right-click your folder/video in File Explorer  
2. Choose **Copy as path**  
3. Click the text field in OmniTag â†’ Ctrl+V to paste  
4. Press Queue Prompt â†’ get PNGs/MP4s + perfect .txt captions ready for training!

ğŸ–¼ï¸ğŸ“ **Batch Folder Mode**  
â†’ Throw any folder at it (images + videos mixed)  
â†’ Captions EVERY .jpg/.png/.webp/.bmp  
â†’ Processes EVERY .mp4/.mov/.avi/.mkv/.webm as segmented clips  
â†’ Middle-frame Qwen3 captioning + optional Whisper audio transcript appended

ğŸ¥ **Single Video File Mode**  
â†’ Pick one video â†’ splits into short segments  
â†’ Optional Whisper speech-to-text at the end of every caption

ğŸ›ï¸ **Everything is adjustable sliders**  
â€¢ Resolution (256â€“1920)  
â€¢ Max tokens (512â€“2048)  
â€¢ FPS output  
â€¢ Segment length (1â€“30s)  
â€¢ Skip frames between segments  
â€¢ Max segments (up to 100!)  

ğŸ”Š **Audio superpowers**  
â€¢ Include original audio in output clips? (Yes/No)  
â€¢ Append transcribed speech to caption end? (Yes/No)  

ğŸ§  **Clinical / unfiltered / exhaustive mode by default**  
Starts every caption with your trigger word (default: ohwx)  
Anti-lazy retry + fallback if model tries to be boring

Perfect for building high-quality LoRA datasets, especially when you want **raw, detailed, uncensored descriptions** without fighting refusal.



Works with 4-bit quantized Qwen3-VL-8B (â‰ˆ10â€“14 GB VRAM)  
First run downloads model automatically (~16 GB)

